{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOorAjn4uNhzC8btFXt7ebC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Atelier Python Session 6 - NLP\n","\n","Aujourd'hui, nous allons aborder le [NLP](https://en.wikipedia.org/wiki/Natural_language_processing) (Natural Language Processing), ou TAL en fran√ßais. Il s'agit d'un ensemble de techniques qui nous permettront d'extraire des informations du contenu textuel."],"metadata":{"id":"zKrg12wGn58s"}},{"cell_type":"markdown","source":["## Tokenisation"],"metadata":{"id":"-IEaCH5Xo_0h"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"EgPVyyc_nvfw","executionInfo":{"status":"ok","timestamp":1732023454075,"user_tz":-60,"elapsed":13382,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}}},"outputs":[],"source":["import nltk"]},{"cell_type":"code","source":["import os\n","\n","def read_txt(path):\n","  with open(path) as f:\n","    return f.read()\n","\n","text = read_txt(os.path.join(os.getcwd(), \"sample_data\", \"README.md\"))"],"metadata":{"id":"xxeGua97pJn1","executionInfo":{"status":"ok","timestamp":1732023678950,"user_tz":-60,"elapsed":218,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize, sent_tokenize\n","\n","nltk.download('punkt_tab') # Download the model"],"metadata":{"id":"n5c-qg9Qp0AF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences = sent_tokenize(text)\n","words = word_tokenize(text)\n","\n","print(sentences)\n","print(words)"],"metadata":{"id":"nyLmdnl7qqZA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Stop words et nettoyage"],"metadata":{"id":"V5VLMnuIsgp9"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","import string"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjiUvFt8sp0u","executionInfo":{"status":"ok","timestamp":1732024446055,"user_tz":-60,"elapsed":228,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"3381887b-56cc-4124-c6cb-dd4d2b7e1b65"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["stop_words = set(stopwords.words('english'))  # NLTK stopwords for English\n","punctuation = set(string.punctuation)\n","\n","print(stop_words)\n","print(punctuation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8q2bA_qnsu1R","executionInfo":{"status":"ok","timestamp":1732024459675,"user_tz":-60,"elapsed":341,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"2329c599-844c-4023-9761-a96d0d0c37e5"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["{'you', 'll', 'if', \"you've\", 'with', 'from', 'that', 'we', 'am', 'themselves', 'what', 'weren', 'he', 'was', 'nor', 'ain', \"mustn't\", 'just', 'after', 'against', 'his', 'don', 'y', 'itself', 'both', 'most', 'further', \"hasn't\", 'over', 'yours', 'where', 'then', 'to', 'out', 'other', \"that'll\", 'or', 'can', 'they', 's', 'hers', 'she', 'these', 'being', 'more', 'him', 'before', 'all', \"isn't\", 't', 'won', 'been', 'myself', \"couldn't\", 'will', 'needn', 'too', 'so', 'her', \"it's\", 'when', \"shan't\", 'me', 'here', 'by', 'wasn', 'only', 'doesn', \"shouldn't\", 'such', 'up', 'through', 'didn', 'between', 'hadn', \"won't\", \"wouldn't\", \"don't\", 'having', 'but', 'shouldn', 'about', 'its', \"you're\", 'any', 'ours', 'were', 'yourself', \"didn't\", 'the', 'down', 'wouldn', 'o', 'which', 'mightn', 'each', 'had', \"needn't\", 'a', 'not', 'their', 'be', 'in', 'your', 'is', 'once', 'as', \"she's\", 'aren', 'mustn', 'doing', 'has', 'theirs', \"wasn't\", 'off', \"should've\", 'our', 'during', 'shan', 'same', 're', 'yourselves', 'd', 'couldn', 'no', 'it', 'below', 'few', 'an', \"hadn't\", \"doesn't\", 'some', 'himself', 'how', 'does', 'herself', 'isn', 'haven', 've', 'above', 'them', 'than', 'own', 'm', 'now', \"you'd\", \"aren't\", 'again', 'those', \"weren't\", 'and', \"you'll\", 'at', 'under', 'until', 'while', 'into', 'this', 'my', 'there', 'whom', 'should', 'on', 'very', 'for', \"haven't\", 'i', 'hasn', 'of', 'who', 'ma', 'why', 'do', 'because', 'ourselves', 'did', \"mightn't\", 'have', 'are'}\n","{'@', '-', \"'\", '\\\\', '!', '/', ';', '<', ':', ',', '`', '*', '=', '>', '|', '.', '}', '%', ')', '?', '~', '&', '+', '{', '_', '#', '\"', '[', '(', '^', '$', ']'}\n"]}]},{"cell_type":"code","source":["filtered = []\n","for word in words:\n","  if word.lower() not in stop_words and word not in punctuation and word.isalpha():\n","    filtered.append(word)\n","words = filtered\n","\n","print(words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJVl_XU7tAcZ","executionInfo":{"status":"ok","timestamp":1732024564524,"user_tz":-60,"elapsed":6,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"54885ce6-6322-41b7-d1ef-884651fe58b1"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["['directory', 'includes', 'sample', 'datasets', 'get', 'started', 'California', 'housing', 'data', 'US', 'Census', 'information', 'available', 'https', 'small', 'sample', 'MNIST', 'database', 'https', 'described', 'http', 'contains', 'copy', 'Anscombe', 'quartet', 'https', 'originally', 'described', 'Anscombe', 'J', 'Statistical', 'Analysis', 'American', 'Statistician', 'JSTOR', 'copy', 'prepared', 'library', 'https']\n"]}]},{"cell_type":"markdown","source":["## POS tagging"],"metadata":{"id":"08NSG7UYro-O"}},{"cell_type":"code","source":["nltk.download('averaged_perceptron_tagger_eng')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4saMVWrSrq3j","executionInfo":{"status":"ok","timestamp":1732024575115,"user_tz":-60,"elapsed":212,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"c4017952-07b1-4295-e60a-a25feda26b00"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["pos_tags = nltk.pos_tag(words)\n","print(pos_tags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeRErbyCruob","executionInfo":{"status":"ok","timestamp":1732024577246,"user_tz":-60,"elapsed":219,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"5007239c-e01d-4008-84ff-ba661c0b6ffc"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["[('directory', 'NN'), ('includes', 'VBZ'), ('sample', 'JJ'), ('datasets', 'NNS'), ('get', 'VBP'), ('started', 'VBN'), ('California', 'NNP'), ('housing', 'NN'), ('data', 'NNS'), ('US', 'NNP'), ('Census', 'NNP'), ('information', 'NN'), ('available', 'JJ'), ('https', 'NN'), ('small', 'JJ'), ('sample', 'JJ'), ('MNIST', 'NNP'), ('database', 'NN'), ('https', 'NN'), ('described', 'VBD'), ('http', 'JJ'), ('contains', 'NNS'), ('copy', 'VBP'), ('Anscombe', 'NNP'), ('quartet', 'NN'), ('https', 'NN'), ('originally', 'RB'), ('described', 'VBN'), ('Anscombe', 'NNP'), ('J', 'NNP'), ('Statistical', 'NNP'), ('Analysis', 'NNP'), ('American', 'NNP'), ('Statistician', 'NNP'), ('JSTOR', 'NNP'), ('copy', 'NN'), ('prepared', 'VBD'), ('library', 'JJ'), ('https', 'NN')]\n"]}]},{"cell_type":"markdown","source":["# Lemmatization"],"metadata":{"id":"keoUXJuWq-Af"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","\n","nltk.download('wordnet')\n","nltk.download('omw-1.4')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"366rkdXDrBsq","executionInfo":{"status":"ok","timestamp":1732023983086,"user_tz":-60,"elapsed":538,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"d121dd02-4997-4380-bcb7-71d845fdd5e2"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["from nltk.corpus import wordnet\n","\n","def get_wordnet_pos(treebank_tag):\n","    if treebank_tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif treebank_tag.startswith('V'):\n","        return wordnet.VERB\n","    elif treebank_tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif treebank_tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return wordnet.NOUN\n","\n","changed = []\n","for word in pos_tags:\n","  changed.append((word[0], get_wordnet_pos(word[1])))\n","pos_tags = changed\n","\n","print(pos_tags)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMqJoHTruK8X","executionInfo":{"status":"ok","timestamp":1732024865704,"user_tz":-60,"elapsed":206,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"9dc387ed-ee86-4a19-e522-7ef458f01e98"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["[('directory', 'n'), ('includes', 'n'), ('sample', 'n'), ('datasets', 'n'), ('get', 'n'), ('started', 'n'), ('California', 'n'), ('housing', 'n'), ('data', 'n'), ('US', 'n'), ('Census', 'n'), ('information', 'n'), ('available', 'n'), ('https', 'n'), ('small', 'n'), ('sample', 'n'), ('MNIST', 'n'), ('database', 'n'), ('https', 'n'), ('described', 'n'), ('http', 'n'), ('contains', 'n'), ('copy', 'n'), ('Anscombe', 'n'), ('quartet', 'n'), ('https', 'n'), ('originally', 'n'), ('described', 'n'), ('Anscombe', 'n'), ('J', 'n'), ('Statistical', 'n'), ('Analysis', 'n'), ('American', 'n'), ('Statistician', 'n'), ('JSTOR', 'n'), ('copy', 'n'), ('prepared', 'n'), ('library', 'n'), ('https', 'n')]\n"]}]},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","lemmas = []\n","\n","for word in pos_tags:\n","  lemma = lemmatizer.lemmatize(word[0], pos = word[1])\n","  lemmas.append({\"original\" : word[0], \"lemma\" : lemma})\n","\n","print(lemmas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_krukZMVrKuC","executionInfo":{"status":"ok","timestamp":1732024907182,"user_tz":-60,"elapsed":230,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"2b007da3-f6aa-48bb-b479-8fbf057e4bf3"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'original': 'directory', 'lemma': 'directory'}, {'original': 'includes', 'lemma': 'includes'}, {'original': 'sample', 'lemma': 'sample'}, {'original': 'datasets', 'lemma': 'datasets'}, {'original': 'get', 'lemma': 'get'}, {'original': 'started', 'lemma': 'started'}, {'original': 'California', 'lemma': 'California'}, {'original': 'housing', 'lemma': 'housing'}, {'original': 'data', 'lemma': 'data'}, {'original': 'US', 'lemma': 'US'}, {'original': 'Census', 'lemma': 'Census'}, {'original': 'information', 'lemma': 'information'}, {'original': 'available', 'lemma': 'available'}, {'original': 'https', 'lemma': 'http'}, {'original': 'small', 'lemma': 'small'}, {'original': 'sample', 'lemma': 'sample'}, {'original': 'MNIST', 'lemma': 'MNIST'}, {'original': 'database', 'lemma': 'database'}, {'original': 'https', 'lemma': 'http'}, {'original': 'described', 'lemma': 'described'}, {'original': 'http', 'lemma': 'http'}, {'original': 'contains', 'lemma': 'contains'}, {'original': 'copy', 'lemma': 'copy'}, {'original': 'Anscombe', 'lemma': 'Anscombe'}, {'original': 'quartet', 'lemma': 'quartet'}, {'original': 'https', 'lemma': 'http'}, {'original': 'originally', 'lemma': 'originally'}, {'original': 'described', 'lemma': 'described'}, {'original': 'Anscombe', 'lemma': 'Anscombe'}, {'original': 'J', 'lemma': 'J'}, {'original': 'Statistical', 'lemma': 'Statistical'}, {'original': 'Analysis', 'lemma': 'Analysis'}, {'original': 'American', 'lemma': 'American'}, {'original': 'Statistician', 'lemma': 'Statistician'}, {'original': 'JSTOR', 'lemma': 'JSTOR'}, {'original': 'copy', 'lemma': 'copy'}, {'original': 'prepared', 'lemma': 'prepared'}, {'original': 'library', 'lemma': 'library'}, {'original': 'https', 'lemma': 'http'}]\n"]}]},{"cell_type":"markdown","source":["# NER"],"metadata":{"id":"OB98f3k2u18b"}},{"cell_type":"code","source":["nltk.download('maxent_ne_chunker_tab')\n","nltk.download('words')\n","\n","from nltk import ne_chunk\n","\n","tokens = word_tokenize(text)\n","pos_tags = nltk.pos_tag(tokens)\n","entities = ne_chunk(pos_tags)\n","print(\"Named Entities (NLTK):\")\n","print(entities)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8LDXY8Sru3Ll","executionInfo":{"status":"ok","timestamp":1732024998528,"user_tz":-60,"elapsed":1144,"user":{"displayName":"Jacob Hart","userId":"14472840021485163346"}},"outputId":"b0c4727d-a1a1-428b-d3e3-87e8fb1297ec"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package maxent_ne_chunker_tab to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Named Entities (NLTK):\n","(S\n","  This/DT\n","  directory/NN\n","  includes/VBZ\n","  a/DT\n","  few/JJ\n","  sample/JJ\n","  datasets/NNS\n","  to/TO\n","  get/VB\n","  you/PRP\n","  started/VBN\n","  ./.\n","  */VB\n","  `/``\n","  california_housing_data/NNS\n","  */''\n","  .csv/JJ\n","  `/``\n","  is/VBZ\n","  (GPE California/NNP)\n","  housing/NN\n","  data/NNS\n","  from/IN\n","  the/DT\n","  1990/CD\n","  (ORGANIZATION US/NNP Census/NNP)\n","  ;/:\n","  more/JJR\n","  information/NN\n","  is/VBZ\n","  available/JJ\n","  at/IN\n","  :/:\n","  https/NN\n","  :/:\n","  //docs.google.com/document/d/e/2PACX-1vRhYtsvc5eOR2FWNCwaBiKL6suIOrxJig8LcSBbmCbyYsayia_DvPOOBlXZ4CAlQ5nlDD8kTaIDRwrN/pub/JJ\n","  */NN\n","  `/``\n","  mnist_/NN\n","  */NN\n","  .csv/NNP\n","  `/``\n","  is/VBZ\n","  a/DT\n","  small/JJ\n","  sample/NN\n","  of/IN\n","  the/DT\n","  [/NNP\n","  MNIST/NNP\n","  database/NN\n","  ]/NNP\n","  (/(\n","  https/NN\n","  :/:\n","  //en.wikipedia.org/wiki/MNIST_database/NN\n","  )/)\n","  ,/,\n","  which/WDT\n","  is/VBZ\n","  described/VBN\n","  at/IN\n","  :/:\n","  http/NN\n","  :/:\n","  //yann.lecun.com/exdb/mnist//JJ\n","  */NNP\n","  `/``\n","  anscombe.json/NN\n","  `/``\n","  contains/VBZ\n","  a/DT\n","  copy/NN\n","  of/IN\n","  [/NNP\n","  Anscombe/NNP\n","  's/POS\n","  quartet/NN\n","  ]/NN\n","  (/(\n","  https/NN\n","  :/:\n","  //en.wikipedia.org/wiki/Anscombe/CD\n","  %/NN\n","  27s_quartet/CD\n","  )/)\n","  ;/:\n","  it/PRP\n","  was/VBD\n","  originally/RB\n","  described/VBN\n","  in/IN\n","  (GPE Anscombe/NNP)\n","  ,/,\n","  F./NNP\n","  J/NNP\n","  ./.\n","  (/(\n","  1973/CD\n","  )/)\n","  ./.\n","  'Graphs/''\n","  in/IN\n","  Statistical/JJ\n","  Analysis/NNP\n","  '/POS\n","  ./.\n","  (ORGANIZATION American/JJ Statistician/NNP)\n","  ./.\n","  27/CD\n","  (/(\n","  1/CD\n","  )/)\n","  :/:\n","  17-21/JJ\n","  ./.\n","  JSTOR/NNP\n","  2682899./CD\n","  and/CC\n","  our/PRP$\n","  copy/NN\n","  was/VBD\n","  prepared/VBN\n","  by/IN\n","  the/DT\n","  [/NNP\n","  vega_datasets/NNS\n","  library/JJ\n","  ]/NNP\n","  (/(\n","  https/NN\n","  :/:\n","  //github.com/altair-viz/vega_datasets/blob/4f67bdaad10f45e3549984e17e1b3088c731503d/vega_datasets/_data/anscombe.json/NN\n","  )/)\n","  ./.)\n"]}]}]}